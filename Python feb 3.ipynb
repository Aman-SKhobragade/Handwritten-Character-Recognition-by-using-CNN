{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f01914",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten, Conv2D, MaxPool2D, Dropout\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SGD, Adam\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "#reading dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Aman Beast\\\\Downloads\\\\A_Z Handwritten Data.csv\").astype('float32')\n",
    "#splitting data\n",
    "print(data.head(10))\n",
    "X = data.drop('0',axis = 1)\n",
    "y = data['0']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "train_x = np.reshape(train_x.values, (train_x.shape[0], 28,28))\n",
    "test_x = np.reshape(test_x.values, (test_x.shape[0], 28,28))\n",
    "\n",
    "print(\"Train data shape: \", train_x.shape)\n",
    "print(\"Test data shape: \", test_x.shape)\n",
    "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}\n",
    "y_int = np.int0(y)\n",
    "count = np.zeros(26, dtype='int')\n",
    "for i in y_int:\n",
    "    count[i] +=1\n",
    "\n",
    "alphabets = []\n",
    "for i in word_dict.values():\n",
    "    alphabets.append(i)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "ax.barh(alphabets, count)\n",
    "\n",
    "plt.xlabel(\"Number of elements \")\n",
    "plt.ylabel(\"Alphabets\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#reshape\n",
    "shuff = shuffle(train_x[:100])\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
    "axes = ax.flatten()\n",
    "\n",
    "for i in range(9):\n",
    "    _, shu = cv2.threshold(shuff[i], 30, 200, cv2.THRESH_BINARY)\n",
    "    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\n",
    "plt.show()\n",
    "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
    "print(\"New shape of train data: \", train_X.shape)\n",
    "\n",
    "test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2],1)\n",
    "print(\"New shape of train data: \", test_X.shape)\n",
    "\n",
    "train_yOHE = to_categorical(train_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of train labels: \", train_yOHE.shape)\n",
    "\n",
    "test_yOHE = to_categorical(test_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of test labels: \", test_yOHE.shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "\n",
    "model.add(Dense(26,activation =\"softmax\"))\n",
    "model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_X, train_yOHE, epochs=1,  validation_data = (test_X,test_yOHE))\n",
    "model.summary()\n",
    "model.save(r'model_hand.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cef259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
